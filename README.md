A Feature-level Modular Neural Network

We test the parameters of the Layer0 update or not if we freeze the Layer2 in the Backpropogation_test.py

Before training:
![image](https://github.com/user-attachments/assets/b75afb59-8042-4f22-a8e1-c08eb86d902b)

After training:
![image](https://github.com/user-attachments/assets/bf0a269b-761a-4c0f-87bf-8d3c0186fb25)

